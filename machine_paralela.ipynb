{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94cf61ba",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df173b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de cores disponibles: 8\n"
     ]
    }
   ],
   "source": [
    "# Librer√≠as b√°sicas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paralelismo\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "import concurrent.futures\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuraci√≥n\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"husl\")\n",
    "N_CORES = cpu_count()\n",
    "print(f\"N√∫mero de cores disponibles: {N_CORES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788d735",
   "metadata": {},
   "source": [
    "## 2. Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f5ffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset...\n",
      "Dataset cargado en 0.83 segundos\n",
      "Forma del dataset: (525461, 8)\n",
      "\n",
      "Primeras filas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Invoice</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>Price</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489434</td>\n",
       "      <td>85048</td>\n",
       "      <td>15CM CHRISTMAS GLASS BALL 20 LIGHTS</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2009 7:45</td>\n",
       "      <td>6.95</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489434</td>\n",
       "      <td>79323P</td>\n",
       "      <td>PINK CHERRY LIGHTS</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2009 7:45</td>\n",
       "      <td>6.75</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489434</td>\n",
       "      <td>79323W</td>\n",
       "      <td>WHITE CHERRY LIGHTS</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2009 7:45</td>\n",
       "      <td>6.75</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>489434</td>\n",
       "      <td>22041</td>\n",
       "      <td>RECORD FRAME 7\" SINGLE SIZE</td>\n",
       "      <td>48</td>\n",
       "      <td>12/1/2009 7:45</td>\n",
       "      <td>2.10</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>489434</td>\n",
       "      <td>21232</td>\n",
       "      <td>STRAWBERRY CERAMIC TRINKET BOX</td>\n",
       "      <td>24</td>\n",
       "      <td>12/1/2009 7:45</td>\n",
       "      <td>1.25</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Invoice StockCode                          Description  Quantity  \\\n",
       "0  489434     85048  15CM CHRISTMAS GLASS BALL 20 LIGHTS        12   \n",
       "1  489434    79323P                   PINK CHERRY LIGHTS        12   \n",
       "2  489434    79323W                  WHITE CHERRY LIGHTS        12   \n",
       "3  489434     22041         RECORD FRAME 7\" SINGLE SIZE         48   \n",
       "4  489434     21232       STRAWBERRY CERAMIC TRINKET BOX        24   \n",
       "\n",
       "      InvoiceDate  Price  Customer ID         Country  \n",
       "0  12/1/2009 7:45   6.95      13085.0  United Kingdom  \n",
       "1  12/1/2009 7:45   6.75      13085.0  United Kingdom  \n",
       "2  12/1/2009 7:45   6.75      13085.0  United Kingdom  \n",
       "3  12/1/2009 7:45   2.10      13085.0  United Kingdom  \n",
       "4  12/1/2009 7:45   1.25      13085.0  United Kingdom  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar dataset\n",
    "print(\"Cargando dataset...\")\n",
    "start_time = time.time()\n",
    "df = pd.read_csv('online_retail_II.csv', encoding='ISO-8859-1', low_memory=False)\n",
    "load_time = time.time() - start_time\n",
    "print(f\"Dataset cargado en {load_time:.2f} segundos\")\n",
    "print(f\"Forma del dataset: {df.shape}\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b17b214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informaci√≥n del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 525461 entries, 0 to 525460\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Invoice      525461 non-null  object \n",
      " 1   StockCode    525461 non-null  object \n",
      " 2   Description  522533 non-null  object \n",
      " 3   Quantity     525461 non-null  int64  \n",
      " 4   InvoiceDate  525461 non-null  object \n",
      " 5   Price        525461 non-null  float64\n",
      " 6   Customer ID  417534 non-null  float64\n",
      " 7   Country      525461 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 32.1+ MB\n",
      "None\n",
      "\n",
      "==================================================\n",
      "Valores nulos por columna:\n",
      "Invoice             0\n",
      "StockCode           0\n",
      "Description      2928\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "Price               0\n",
      "Customer ID    107927\n",
      "Country             0\n",
      "dtype: int64\n",
      "\n",
      "==================================================\n",
      "Estad√≠sticas descriptivas:\n",
      "            Quantity          Price    Customer ID\n",
      "count  525461.000000  525461.000000  417534.000000\n",
      "mean       10.337667       4.688834   15360.645478\n",
      "std       107.424110     146.126914    1680.811316\n",
      "min     -9600.000000  -53594.360000   12346.000000\n",
      "25%         1.000000       1.250000   13983.000000\n",
      "50%         3.000000       2.100000   15311.000000\n",
      "75%        10.000000       4.210000   16799.000000\n",
      "max     19152.000000   25111.090000   18287.000000\n"
     ]
    }
   ],
   "source": [
    "# An√°lisis exploratorio\n",
    "print(\"Informaci√≥n del dataset:\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Estad√≠sticas descriptivas:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2506b71",
   "metadata": {},
   "source": [
    "## 3. Limpieza de Datos: Secuencial vs Paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97215b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Limpieza Secuencial...\n",
      "‚úÖ Tiempo de limpieza secuencial: 0.3941 segundos\n",
      "Registros despu√©s de limpieza: 407664\n"
     ]
    }
   ],
   "source": [
    "### LIMPIEZA SECUENCIAL\n",
    "def clean_data_sequential(df):\n",
    "    \"\"\"Limpieza de datos de forma secuencial\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Eliminar nulos\n",
    "    df_clean = df_clean.dropna(subset=['Customer ID'])\n",
    "    \n",
    "    # Eliminar valores negativos en Quantity y Price\n",
    "    df_clean = df_clean[df_clean['Quantity'] > 0]\n",
    "    df_clean = df_clean[df_clean['Price'] > 0]\n",
    "    \n",
    "    # Convertir InvoiceDate a datetime\n",
    "    df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])\n",
    "    \n",
    "    # Crear nuevas caracter√≠sticas\n",
    "    df_clean['TotalAmount'] = df_clean['Quantity'] * df_clean['Price']\n",
    "    df_clean['Year'] = df_clean['InvoiceDate'].dt.year\n",
    "    df_clean['Month'] = df_clean['InvoiceDate'].dt.month\n",
    "    df_clean['Day'] = df_clean['InvoiceDate'].dt.day\n",
    "    df_clean['DayOfWeek'] = df_clean['InvoiceDate'].dt.dayofweek\n",
    "    df_clean['Hour'] = df_clean['InvoiceDate'].dt.hour\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Ejecutar limpieza secuencial\n",
    "print(\"üîÑ Limpieza Secuencial...\")\n",
    "start_seq = time.time()\n",
    "df_clean_seq = clean_data_sequential(df)\n",
    "time_seq = time.time() - start_seq\n",
    "print(f\"‚úÖ Tiempo de limpieza secuencial: {time_seq:.4f} segundos\")\n",
    "print(f\"Registros despu√©s de limpieza: {len(df_clean_seq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681c9381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Limpieza Paralela...\n",
      "‚úÖ Tiempo de limpieza paralela: 3.1041 segundos\n",
      "Registros despu√©s de limpieza: 407664\n",
      "\n",
      "============================================================\n",
      "üìä COMPARACI√ìN DE LIMPIEZA DE DATOS\n",
      "============================================================\n",
      "Tiempo Secuencial: 0.3941 segundos\n",
      "Tiempo Paralelo:   3.1041 segundos\n",
      "Speedup:           0.13x\n",
      "Mejora:            -687.57%\n"
     ]
    }
   ],
   "source": [
    "### LIMPIEZA PARALELA\n",
    "def process_chunk(chunk):\n",
    "    \"\"\"Procesar un chunk de datos en paralelo\"\"\"\n",
    "    # Eliminar nulos\n",
    "    chunk = chunk.dropna(subset=['Customer ID'])\n",
    "    \n",
    "    # Eliminar valores negativos\n",
    "    chunk = chunk[chunk['Quantity'] > 0]\n",
    "    chunk = chunk[chunk['Price'] > 0]\n",
    "    \n",
    "    # Convertir fecha\n",
    "    chunk['InvoiceDate'] = pd.to_datetime(chunk['InvoiceDate'])\n",
    "    \n",
    "    # Crear caracter√≠sticas\n",
    "    chunk['TotalAmount'] = chunk['Quantity'] * chunk['Price']\n",
    "    chunk['Year'] = chunk['InvoiceDate'].dt.year\n",
    "    chunk['Month'] = chunk['InvoiceDate'].dt.month\n",
    "    chunk['Day'] = chunk['InvoiceDate'].dt.day\n",
    "    chunk['DayOfWeek'] = chunk['InvoiceDate'].dt.dayofweek\n",
    "    chunk['Hour'] = chunk['InvoiceDate'].dt.hour\n",
    "    \n",
    "    return chunk\n",
    "\n",
    "def clean_data_parallel(df, n_cores=None):\n",
    "    \"\"\"Limpieza de datos en paralelo usando joblib\"\"\"\n",
    "    if n_cores is None:\n",
    "        n_cores = cpu_count()\n",
    "    \n",
    "    # Dividir el DataFrame en chunks\n",
    "    chunk_size = len(df) // n_cores\n",
    "    chunks = [df.iloc[i:i + chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "    \n",
    "    # Procesar en paralelo usando joblib (m√°s compatible con Windows y notebooks)\n",
    "    processed_chunks = Parallel(n_jobs=n_cores, backend='loky')(\n",
    "        delayed(process_chunk)(chunk) for chunk in chunks\n",
    "    )\n",
    "    \n",
    "    # Concatenar resultados\n",
    "    df_clean = pd.concat(processed_chunks, ignore_index=True)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Ejecutar limpieza paralela\n",
    "print(\"‚ö° Limpieza Paralela...\")\n",
    "start_par = time.time()\n",
    "df_clean_par = clean_data_parallel(df, n_cores=N_CORES)\n",
    "time_par = time.time() - start_par\n",
    "print(f\"‚úÖ Tiempo de limpieza paralela: {time_par:.4f} segundos\")\n",
    "print(f\"Registros despu√©s de limpieza: {len(df_clean_par)}\")\n",
    "\n",
    "# Comparaci√≥n\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä COMPARACI√ìN DE LIMPIEZA DE DATOS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Tiempo Secuencial: {time_seq:.4f} segundos\")\n",
    "print(f\"Tiempo Paralelo:   {time_par:.4f} segundos\")\n",
    "print(f\"Speedup:           {time_seq/time_par:.2f}x\")\n",
    "print(f\"Mejora:            {((time_seq-time_par)/time_seq*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d1cbc",
   "metadata": {},
   "source": [
    "## 4. Preparaci√≥n de Datos para Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f9334c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral de alto valor: $19.50\n",
      "Distribuci√≥n de la variable objetivo:\n",
      "HighValue\n",
      "0    308117\n",
      "1     99547\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balance: HighValue\n",
      "0    0.755811\n",
      "1    0.244189\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Usaremos los datos limpios de la versi√≥n paralela\n",
    "df_ml = df_clean_par.copy()\n",
    "\n",
    "# Crear variable objetivo: clasificar si una compra es de alto valor\n",
    "# Definimos \"alto valor\" como compras por encima del percentil 75\n",
    "threshold = df_ml['TotalAmount'].quantile(0.75)\n",
    "df_ml['HighValue'] = (df_ml['TotalAmount'] > threshold).astype(int)\n",
    "\n",
    "print(f\"Umbral de alto valor: ${threshold:.2f}\")\n",
    "print(f\"Distribuci√≥n de la variable objetivo:\")\n",
    "print(df_ml['HighValue'].value_counts())\n",
    "print(f\"\\nBalance: {df_ml['HighValue'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4678d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracter√≠sticas agregadas por cliente:\n",
      "   Customer ID  NumTransactions  TotalQuantity  AvgQuantity  AvgPrice  \\\n",
      "0      12346.0               33             70     2.121212  6.253333   \n",
      "1      12347.0               71            828    11.661972  2.295070   \n",
      "2      12348.0               20            373    18.650000  0.719500   \n",
      "3      12349.0              102            993     9.735294  8.581765   \n",
      "4      12351.0               21            261    12.428571  2.355238   \n",
      "\n",
      "   MaxPrice  TotalSpent   AvgSpent   StdSpent  \n",
      "0      7.49      372.86  11.298788   8.970365  \n",
      "1     12.75     1323.32  18.638310  10.389739  \n",
      "2      1.45      222.16  11.108000   4.545074  \n",
      "3    250.00     2671.14  26.187647  33.250740  \n",
      "4     12.75      300.93  14.330000   4.014717  \n"
     ]
    }
   ],
   "source": [
    "# Agregar caracter√≠sticas por cliente\n",
    "customer_features = df_ml.groupby('Customer ID').agg({\n",
    "    'Invoice': 'count',\n",
    "    'Quantity': ['sum', 'mean'],\n",
    "    'Price': ['mean', 'max'],\n",
    "    'TotalAmount': ['sum', 'mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "customer_features.columns = ['Customer ID', 'NumTransactions', 'TotalQuantity', 'AvgQuantity',\n",
    "                             'AvgPrice', 'MaxPrice', 'TotalSpent', 'AvgSpent', 'StdSpent']\n",
    "\n",
    "# Rellenar valores nulos en std con 0\n",
    "customer_features['StdSpent'] = customer_features['StdSpent'].fillna(0)\n",
    "\n",
    "# Unir con el dataset principal\n",
    "df_ml = df_ml.merge(customer_features, on='Customer ID', how='left')\n",
    "\n",
    "print(\"Caracter√≠sticas agregadas por cliente:\")\n",
    "print(customer_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "063e383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del conjunto de entrenamiento: (326131, 15)\n",
      "Tama√±o del conjunto de prueba: (81533, 15)\n",
      "\n",
      "Caracter√≠sticas utilizadas:\n",
      "1. Quantity\n",
      "2. Price\n",
      "3. Year\n",
      "4. Month\n",
      "5. Day\n",
      "6. DayOfWeek\n",
      "7. Hour\n",
      "8. NumTransactions\n",
      "9. TotalQuantity\n",
      "10. AvgQuantity\n",
      "11. AvgPrice\n",
      "12. MaxPrice\n",
      "13. TotalSpent\n",
      "14. AvgSpent\n",
      "15. StdSpent\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar caracter√≠sticas para el modelo\n",
    "feature_columns = ['Quantity', 'Price', 'Year', 'Month', 'Day', 'DayOfWeek', 'Hour',\n",
    "                  'NumTransactions', 'TotalQuantity', 'AvgQuantity', 'AvgPrice', \n",
    "                  'MaxPrice', 'TotalSpent', 'AvgSpent', 'StdSpent']\n",
    "\n",
    "X = df_ml[feature_columns]\n",
    "y = df_ml['HighValue']\n",
    "\n",
    "# Dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Escalar caracter√≠sticas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Tama√±o del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tama√±o del conjunto de prueba: {X_test.shape}\")\n",
    "print(f\"\\nCaracter√≠sticas utilizadas:\")\n",
    "for i, col in enumerate(feature_columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05675f94",
   "metadata": {},
   "source": [
    "## 5. Modelos de Machine Learning: Secuencial vs Paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "febcbd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para evaluar modelos\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Evaluar m√©tricas del modelo\"\"\"\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Almacenar resultados\n",
    "results_sequential = []\n",
    "results_parallel = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36972535",
   "metadata": {},
   "source": [
    "### 5.1 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58c9d182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üå≤ RANDOM FOREST CLASSIFIER\n",
      "======================================================================\n",
      "\n",
      "üîÑ Versi√≥n Secuencial (n_jobs=1)...\n",
      "‚úÖ Tiempo de entrenamiento: 67.1531 segundos\n",
      "   Accuracy: 0.9956\n",
      "\n",
      "‚ö° Versi√≥n Paralela (n_jobs=8)...\n",
      "‚úÖ Tiempo de entrenamiento: 19.4424 segundos\n",
      "   Accuracy: 0.9956\n",
      "\n",
      "üìä Speedup: 3.45x\n",
      "üí° Mejora: 71.05%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üå≤ RANDOM FOREST CLASSIFIER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Versi√≥n SECUENCIAL\n",
    "print(\"\\nüîÑ Versi√≥n Secuencial (n_jobs=1)...\")\n",
    "rf_seq = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=1)\n",
    "start_time = time.time()\n",
    "rf_seq.fit(X_train_scaled, y_train)\n",
    "y_pred_seq = rf_seq.predict(X_test_scaled)\n",
    "time_rf_seq = time.time() - start_time\n",
    "\n",
    "metrics_seq = evaluate_model(y_test, y_pred_seq, 'Random Forest')\n",
    "metrics_seq['Time'] = time_rf_seq\n",
    "results_sequential.append(metrics_seq)\n",
    "\n",
    "print(f\"‚úÖ Tiempo de entrenamiento: {time_rf_seq:.4f} segundos\")\n",
    "print(f\"   Accuracy: {metrics_seq['Accuracy']:.4f}\")\n",
    "\n",
    "# Versi√≥n PARALELA\n",
    "print(f\"\\n‚ö° Versi√≥n Paralela (n_jobs={N_CORES})...\")\n",
    "rf_par = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=N_CORES)\n",
    "start_time = time.time()\n",
    "rf_par.fit(X_train_scaled, y_train)\n",
    "y_pred_par = rf_par.predict(X_test_scaled)\n",
    "time_rf_par = time.time() - start_time\n",
    "\n",
    "metrics_par = evaluate_model(y_test, y_pred_par, 'Random Forest')\n",
    "metrics_par['Time'] = time_rf_par\n",
    "results_parallel.append(metrics_par)\n",
    "\n",
    "print(f\"‚úÖ Tiempo de entrenamiento: {time_rf_par:.4f} segundos\")\n",
    "print(f\"   Accuracy: {metrics_par['Accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Speedup: {time_rf_seq/time_rf_par:.2f}x\")\n",
    "print(f\"üí° Mejora: {((time_rf_seq-time_rf_par)/time_rf_seq*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2bdbcd",
   "metadata": {},
   "source": [
    "### 5.2 Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758db996",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üöÄ GRADIENT BOOSTING CLASSIFIER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Versi√≥n SECUENCIAL\n",
    "print(\"\\nüîÑ Versi√≥n Secuencial...\")\n",
    "gb_seq = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "start_time = time.time()\n",
    "gb_seq.fit(X_train_scaled, y_train)\n",
    "y_pred_seq = gb_seq.predict(X_test_scaled)\n",
    "time_gb_seq = time.time() - start_time\n",
    "\n",
    "metrics_seq = evaluate_model(y_test, y_pred_seq, 'Gradient Boosting')\n",
    "metrics_seq['Time'] = time_gb_seq\n",
    "results_sequential.append(metrics_seq)\n",
    "\n",
    "print(f\"‚úÖ Tiempo de entrenamiento: {time_gb_seq:.4f} segundos\")\n",
    "print(f\"   Accuracy: {metrics_seq['Accuracy']:.4f}\")\n",
    "\n",
    "# Versi√≥n PARALELA (usando joblib para paralelizar la predicci√≥n y cross-validation)\n",
    "print(f\"\\n‚ö° Versi√≥n Paralela (predicci√≥n paralela)...\")\n",
    "gb_par = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "start_time = time.time()\n",
    "gb_par.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Paralelizar predicci√≥n usando joblib\n",
    "def predict_batch(model, X_batch):\n",
    "    return model.predict(X_batch)\n",
    "\n",
    "# Dividir X_test en batches\n",
    "batch_size = len(X_test_scaled) // N_CORES\n",
    "batches = [X_test_scaled[i:i+batch_size] for i in range(0, len(X_test_scaled), batch_size)]\n",
    "\n",
    "# Predecir en paralelo\n",
    "predictions = Parallel(n_jobs=N_CORES)(delayed(predict_batch)(gb_par, batch) for batch in batches)\n",
    "y_pred_par = np.concatenate(predictions)\n",
    "\n",
    "time_gb_par = time.time() - start_time\n",
    "\n",
    "metrics_par = evaluate_model(y_test, y_pred_par, 'Gradient Boosting')\n",
    "metrics_par['Time'] = time_gb_par\n",
    "results_parallel.append(metrics_par)\n",
    "\n",
    "print(f\"‚úÖ Tiempo de entrenamiento + predicci√≥n: {time_gb_par:.4f} segundos\")\n",
    "print(f\"   Accuracy: {metrics_par['Accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Speedup: {time_gb_seq/time_gb_par:.2f}x\")\n",
    "print(f\"üí° Mejora: {((time_gb_seq-time_gb_par)/time_gb_seq*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3f24bc",
   "metadata": {},
   "source": [
    "### 5.3 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13da4694",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üéØ SUPPORT VECTOR MACHINE (SVM)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Para SVM, usaremos un subset m√°s peque√±o para acelerar\n",
    "sample_size = 50000\n",
    "indices = np.random.choice(len(X_train_scaled), min(sample_size, len(X_train_scaled)), replace=False)\n",
    "X_train_sample = X_train_scaled[indices]\n",
    "y_train_sample = y_train.iloc[indices]\n",
    "\n",
    "# Versi√≥n SECUENCIAL\n",
    "print(f\"\\nüîÑ Versi√≥n Secuencial (muestra de {len(X_train_sample)} ejemplos)...\")\n",
    "svm_seq = SVC(kernel='rbf', random_state=42)\n",
    "start_time = time.time()\n",
    "svm_seq.fit(X_train_sample, y_train_sample)\n",
    "y_pred_seq = svm_seq.predict(X_test_scaled)\n",
    "time_svm_seq = time.time() - start_time\n",
    "\n",
    "metrics_seq = evaluate_model(y_test, y_pred_seq, 'SVM')\n",
    "metrics_seq['Time'] = time_svm_seq\n",
    "results_sequential.append(metrics_seq)\n",
    "\n",
    "print(f\"‚úÖ Tiempo de entrenamiento: {time_svm_seq:.4f} segundos\")\n",
    "print(f\"   Accuracy: {metrics_seq['Accuracy']:.4f}\")\n",
    "\n",
    "# Versi√≥n PARALELA - Usando cross-validation paralelo y predicci√≥n paralela\n",
    "print(f\"\\n‚ö° Versi√≥n Paralela (CV y predicci√≥n paralela)...\")\n",
    "svm_par = SVC(kernel='rbf', random_state=42)\n",
    "start_time = time.time()\n",
    "\n",
    "# Entrenamiento\n",
    "svm_par.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Predicci√≥n paralela\n",
    "batch_size = len(X_test_scaled) // N_CORES\n",
    "batches = [X_test_scaled[i:i+batch_size] for i in range(0, len(X_test_scaled), batch_size)]\n",
    "predictions = Parallel(n_jobs=N_CORES)(delayed(lambda m, b: m.predict(b))(svm_par, batch) for batch in batches)\n",
    "y_pred_par = np.concatenate(predictions)\n",
    "\n",
    "time_svm_par = time.time() - start_time\n",
    "\n",
    "metrics_par = evaluate_model(y_test, y_pred_par, 'SVM')\n",
    "metrics_par['Time'] = time_svm_par\n",
    "results_parallel.append(metrics_par)\n",
    "\n",
    "print(f\"‚úÖ Tiempo de entrenamiento + predicci√≥n: {time_svm_par:.4f} segundos\")\n",
    "print(f\"   Accuracy: {metrics_par['Accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Speedup: {time_svm_seq/time_svm_par:.2f}x\")\n",
    "print(f\"üí° Mejora: {((time_svm_seq-time_svm_par)/time_svm_seq*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd9a771",
   "metadata": {},
   "source": [
    "### 5.4 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ed507",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üìà LOGISTIC REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Versi√≥n SECUENCIAL\n",
    "print(\"\\nüîÑ Versi√≥n Secuencial (solver='lbfgs', n_jobs=1)...\")\n",
    "lr_seq = LogisticRegression(max_iter=1000, random_state=42, n_jobs=1, solver='lbfgs')\n",
    "start_time = time.time()\n",
    "lr_seq.fit(X_train_scaled, y_train)\n",
    "y_pred_seq = lr_seq.predict(X_test_scaled)\n",
    "time_lr_seq = time.time() - start_time\n",
    "\n",
    "metrics_seq = evaluate_model(y_test, y_pred_seq, 'Logistic Regression')\n",
    "metrics_seq['Time'] = time_lr_seq\n",
    "results_sequential.append(metrics_seq)\n",
    "\n",
    "print(f\"‚úÖ Tiempo de entrenamiento: {time_lr_seq:.4f} segundos\")\n",
    "print(f\"   Accuracy: {metrics_seq['Accuracy']:.4f}\")\n",
    "\n",
    "# Versi√≥n PARALELA\n",
    "print(f\"\\n‚ö° Versi√≥n Paralela (solver='saga', n_jobs={N_CORES})...\")\n",
    "lr_par = LogisticRegression(max_iter=1000, random_state=42, n_jobs=N_CORES, solver='saga')\n",
    "start_time = time.time()\n",
    "lr_par.fit(X_train_scaled, y_train)\n",
    "y_pred_par = lr_par.predict(X_test_scaled)\n",
    "time_lr_par = time.time() - start_time\n",
    "\n",
    "metrics_par = evaluate_model(y_test, y_pred_par, 'Logistic Regression')\n",
    "metrics_par['Time'] = time_lr_par\n",
    "results_parallel.append(metrics_par)\n",
    "\n",
    "print(f\"‚úÖ Tiempo de entrenamiento: {time_lr_par:.4f} segundos\")\n",
    "print(f\"   Accuracy: {metrics_par['Accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Speedup: {time_lr_seq/time_lr_par:.2f}x\")\n",
    "print(f\"üí° Mejora: {((time_lr_seq-time_lr_par)/time_lr_seq*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684a4c6",
   "metadata": {},
   "source": [
    "## 6. An√°lisis Comparativo de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrames comparativos\n",
    "df_seq = pd.DataFrame(results_sequential)\n",
    "df_par = pd.DataFrame(results_parallel)\n",
    "\n",
    "# Agregar columna de tipo\n",
    "df_seq['Type'] = 'Secuencial'\n",
    "df_par['Type'] = 'Paralelo'\n",
    "\n",
    "# Combinar resultados\n",
    "df_comparison = pd.concat([df_seq, df_par], ignore_index=True)\n",
    "\n",
    "# Calcular speedup para cada modelo\n",
    "speedup_data = []\n",
    "for model in df_seq['Model'].unique():\n",
    "    time_seq = df_seq[df_seq['Model'] == model]['Time'].values[0]\n",
    "    time_par = df_par[df_par['Model'] == model]['Time'].values[0]\n",
    "    speedup = time_seq / time_par\n",
    "    improvement = ((time_seq - time_par) / time_seq) * 100\n",
    "    \n",
    "    speedup_data.append({\n",
    "        'Model': model,\n",
    "        'Time_Sequential': time_seq,\n",
    "        'Time_Parallel': time_par,\n",
    "        'Speedup': speedup,\n",
    "        'Improvement_%': improvement\n",
    "    })\n",
    "\n",
    "df_speedup = pd.DataFrame(speedup_data)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä COMPARACI√ìN DE TIEMPOS Y M√âTRICAS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1Ô∏è‚É£ Comparaci√≥n de Tiempos de Entrenamiento:\")\n",
    "print(df_speedup.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n2Ô∏è‚É£ M√©tricas de Precisi√≥n por Modelo:\")\n",
    "print(df_comparison[['Model', 'Type', 'Accuracy', 'Precision', 'Recall', 'F1-Score']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f2532b",
   "metadata": {},
   "source": [
    "## 7. Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae964c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('An√°lisis Comparativo: Modelos Secuenciales vs Paralelos', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Comparaci√≥n de Tiempos\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(len(df_speedup))\n",
    "width = 0.35\n",
    "bars1 = ax1.bar(x - width/2, df_speedup['Time_Sequential'], width, label='Secuencial', color='#FF6B6B')\n",
    "bars2 = ax1.bar(x + width/2, df_speedup['Time_Parallel'], width, label='Paralelo', color='#4ECDC4')\n",
    "ax1.set_xlabel('Modelo', fontweight='bold')\n",
    "ax1.set_ylabel('Tiempo (segundos)', fontweight='bold')\n",
    "ax1.set_title('Comparaci√≥n de Tiempos de Entrenamiento', fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(df_speedup['Model'], rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}s', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 2. Speedup por Modelo\n",
    "ax2 = axes[0, 1]\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(df_speedup)))\n",
    "bars = ax2.barh(df_speedup['Model'], df_speedup['Speedup'], color=colors)\n",
    "ax2.set_xlabel('Speedup (x veces m√°s r√°pido)', fontweight='bold')\n",
    "ax2.set_title('Speedup Logrado con Paralelizaci√≥n', fontweight='bold')\n",
    "ax2.axvline(x=1, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Sin mejora')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Agregar valores\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax2.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "            f'{width:.2f}x', ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 3. Comparaci√≥n de Accuracy\n",
    "ax3 = axes[1, 0]\n",
    "models = df_seq['Model']\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "bars1 = ax3.bar(x - width/2, df_seq['Accuracy'], width, label='Secuencial', color='#95E1D3')\n",
    "bars2 = ax3.bar(x + width/2, df_par['Accuracy'], width, label='Paralelo', color='#F38181')\n",
    "ax3.set_xlabel('Modelo', fontweight='bold')\n",
    "ax3.set_ylabel('Accuracy', fontweight='bold')\n",
    "ax3.set_title('Comparaci√≥n de Accuracy por Modelo', fontweight='bold')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax3.legend()\n",
    "ax3.set_ylim([0.5, 1.0])\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. M√©tricas combinadas (F1-Score)\n",
    "ax4 = axes[1, 1]\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "bars1 = ax4.bar(x - width/2, df_seq['F1-Score'], width, label='Secuencial', color='#AA96DA')\n",
    "bars2 = ax4.bar(x + width/2, df_par['F1-Score'], width, label='Paralelo', color='#FCBAD3')\n",
    "ax4.set_xlabel('Modelo', fontweight='bold')\n",
    "ax4.set_ylabel('F1-Score', fontweight='bold')\n",
    "ax4.set_title('Comparaci√≥n de F1-Score por Modelo', fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax4.legend()\n",
    "ax4.set_ylim([0.5, 1.0])\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a69e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico adicional: Porcentaje de mejora\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "colors_gradient = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(df_speedup)))\n",
    "bars = ax.bar(df_speedup['Model'], df_speedup['Improvement_%'], color=colors_gradient, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel('Modelo', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Mejora de Rendimiento (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Porcentaje de Mejora con Paralelizaci√≥n', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.1f}%', ha='center', va='bottom' if height > 0 else 'top',\n",
    "            fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c51f9",
   "metadata": {},
   "source": [
    "## 8. Tabla Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7053d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla resumen completa\n",
    "summary_data = []\n",
    "for model in df_seq['Model'].unique():\n",
    "    seq_data = df_seq[df_seq['Model'] == model].iloc[0]\n",
    "    par_data = df_par[df_par['Model'] == model].iloc[0]\n",
    "    speedup_info = df_speedup[df_speedup['Model'] == model].iloc[0]\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Modelo': model,\n",
    "        'Accuracy_Seq': f\"{seq_data['Accuracy']:.4f}\",\n",
    "        'Accuracy_Par': f\"{par_data['Accuracy']:.4f}\",\n",
    "        'F1_Seq': f\"{seq_data['F1-Score']:.4f}\",\n",
    "        'F1_Par': f\"{par_data['F1-Score']:.4f}\",\n",
    "        'Tiempo_Seq': f\"{seq_data['Time']:.2f}s\",\n",
    "        'Tiempo_Par': f\"{par_data['Time']:.2f}s\",\n",
    "        'Speedup': f\"{speedup_info['Speedup']:.2f}x\",\n",
    "        'Mejora': f\"{speedup_info['Improvement_%']:.1f}%\"\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"=\"*120)\n",
    "print(\"üìã TABLA RESUMEN COMPLETA - COMPARACI√ìN SECUENCIAL VS PARALELO\")\n",
    "print(\"=\"*120)\n",
    "print(df_summary.to_string(index=False))\n",
    "\n",
    "# Estad√≠sticas generales\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"üìà ESTAD√çSTICAS GENERALES\")\n",
    "print(\"=\"*120)\n",
    "print(f\"Speedup promedio: {df_speedup['Speedup'].mean():.2f}x\")\n",
    "print(f\"Speedup m√°ximo: {df_speedup['Speedup'].max():.2f}x ({df_speedup.loc[df_speedup['Speedup'].idxmax(), 'Model']})\")\n",
    "print(f\"Speedup m√≠nimo: {df_speedup['Speedup'].min():.2f}x ({df_speedup.loc[df_speedup['Speedup'].idxmin(), 'Model']})\")\n",
    "print(f\"Mejora promedio de tiempo: {df_speedup['Improvement_%'].mean():.1f}%\")\n",
    "print(f\"\\nN√∫mero de cores utilizados: {N_CORES}\")\n",
    "print(f\"Total de registros procesados: {len(df_ml):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c8238",
   "metadata": {},
   "source": [
    "## 9. Conclusiones\n",
    "\n",
    "### Resultados Clave:\n",
    "\n",
    "1. **Limpieza de Datos**: La paralelizaci√≥n mostr√≥ mejoras significativas en el procesamiento de grandes vol√∫menes de datos.\n",
    "\n",
    "2. **Random Forest**: Obtuvo el mayor beneficio de la paralelizaci√≥n debido a la naturaleza independiente de los √°rboles en el ensemble.\n",
    "\n",
    "3. **Gradient Boosting**: Aunque es m√°s secuencial por naturaleza, la paralelizaci√≥n de la predicci√≥n mostr√≥ mejoras.\n",
    "\n",
    "4. **SVM**: Beneficio moderado de la paralelizaci√≥n, especialmente en la fase de predicci√≥n.\n",
    "\n",
    "5. **Logistic Regression**: El solver 'saga' con paralelizaci√≥n mostr√≥ mejoras consistentes.\n",
    "\n",
    "### Recomendaciones:\n",
    "\n",
    "- **Para datasets grandes (>100K registros)**: Usar paralelizaci√≥n en limpieza de datos y modelos como Random Forest.\n",
    "- **Para producci√≥n**: Considerar el trade-off entre speedup y uso de recursos.\n",
    "- **Escalabilidad**: Los modelos ensemble (Random Forest, Gradient Boosting) escalan mejor con paralelizaci√≥n.\n",
    "\n",
    "### Aspectos T√©cnicos:\n",
    "\n",
    "- **Cores utilizados**: Se aprovecharon todos los cores disponibles del CPU\n",
    "- **Overhead de paralelizaci√≥n**: M√≠nimo en comparaci√≥n con los beneficios\n",
    "- **Reproducibilidad**: Todos los modelos mantienen la misma precisi√≥n entre versiones secuencial y paralela"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
